{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API Яндекс погоды**\n",
    "- Прогноз доступен только на 4 дня, соотвествующая проверка есть в решении. Дождь в феврале идёт редко, поэтому в csv переменная 'is_rainy' содержит только значение 0. Проверяла для снега, прогноз снегопадов выгружается.\n",
    "\n",
    "- Для демонстрации ускорения получения данных через API выбрала подход с использованием asyncio. Этот метод особенно эффективен в случае выполнения большого количества ограниченных задач ввода-вывода, таких как HTTP-запросы к API погоды, что позволяет оптимизировать использование ресурсов и сократить временные задержки при получении и обработке данных.\n",
    "\n",
    "- Для ускоренного получения данных по API можно также кэшировать данные, например, при помощи декоратора functools.lru_cache, или применить метод параллельного выполнения задач, например, при помощи модуля concurrent.futures.ThreadPoolExecutor.\n",
    "\n",
    "- В Airflow можно ускорить получение данных API, используя параллельное выполнение задач с помощью библиотеки типа Celery или Dask, которые позволяют запускать задачи в распределенном режиме на нескольких рабочих узлах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import os\n",
    "import aiohttp\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "async def fetch_weather(session, api_key, city):\n",
    "    \"\"\"\n",
    "    Асинхронная функция для получения прогноза дождя для заданного города.\n",
    "    \n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): Сессия для выполнения HTTP-запросов.\n",
    "        api_key (str): API ключ для доступа к API Яндекс.Погоды.\n",
    "        city (dict): Словарь с информацией о городе (название, широта, долгота).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Кортеж с названием города и списком прогнозов погоды.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.weather.yandex.ru/v2/forecast?lat={city['lat']}&lon={city['lon']}&extra=true\"\n",
    "    headers = {\"X-Yandex-API-Key\": api_key}\n",
    "    \n",
    "    async with session.get(url, headers=headers) as response:\n",
    "        data = await response.json()\n",
    "        return city['name'], data.get('forecasts', [])\n",
    "\n",
    "\n",
    "async def get_weather_forecast(api_key, cities):\n",
    "    \"\"\"\n",
    "    Асинхронная функция для получения прогноза дождя для всех заданных городов и записи результатов в CSV файл.\n",
    "    \n",
    "    Args:\n",
    "        api_key (str): API ключ для доступа к API Яндекс.Погоды.\n",
    "        cities (list): Список словарей с информацией о городах.\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_weather(session, api_key, city) for city in cities]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \"\"\"\n",
    "        Вывод уникальных дат.\n",
    "        \"\"\"\n",
    "        unique_dates = set()\n",
    "        for city_name, forecasts in results:\n",
    "            for forecast in forecasts:\n",
    "                date = forecast.get('date', '')\n",
    "                if date:\n",
    "                    unique_dates.add(date)\n",
    "        print(\"Уникальные даты:\", unique_dates)\n",
    "        \n",
    "        with open('weather_forecast_asyncio.csv', mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"city\", \"date\", \"hour\", \"temperature_c\", \"pressure_mm\", \"is_rainy\"])\n",
    "            for city_name, forecasts in results:\n",
    "                print(f\"Полный ответ от API для города {city_name}:\")\n",
    "                for forecast in forecasts:\n",
    "                    date = forecast.get('date', '')\n",
    "                    print(\"Прогноз для даты\", date)\n",
    "                    hours_forecast = forecast.get('hours', [])\n",
    "                    print(\"Количество часов прогноза:\", len(hours_forecast))\n",
    "                    \"\"\"\n",
    "                    Проверяем, есть ли прогноз на часы.\n",
    "                    \"\"\"\n",
    "                    if len(hours_forecast) > 0:\n",
    "                        for hour_data in hours_forecast:\n",
    "                            hour = hour_data.get('hour', '')\n",
    "                            temperature_c = hour_data.get('temp', '')\n",
    "                            pressure_mm = hour_data.get('pressure_mm', '')\n",
    "                            condition = hour_data.get('condition', '')\n",
    "                            is_rainy = 1 if 'rain' in condition else 0\n",
    "                            if date and hour != '' and temperature_c and pressure_mm:\n",
    "                                writer.writerow([city_name, date, hour, temperature_c, pressure_mm, is_rainy])\n",
    "                print()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Асинхронная основная функция программы.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"YANDEX_WEATHER_API_KEY\")\n",
    "\n",
    "    cities = [\n",
    "        {\"name\": \"Москва\", \"lat\": 55.755826, \"lon\": 37.6172999},\n",
    "        {\"name\": \"Казань\", \"lat\": 55.830431, \"lon\": 49.066082},\n",
    "        {\"name\": \"Санкт-Петербург\", \"lat\": 59.9342802, \"lon\": 30.3350986},\n",
    "        {\"name\": \"Тула\", \"lat\": 54.202, \"lon\": 37.644},\n",
    "        {\"name\": \"Новосибирск\", \"lat\": 55.0083526, \"lon\": 82.9357327}\n",
    "    ]\n",
    "\n",
    "    await get_weather_forecast(api_key, cities)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "    if loop and loop.is_running():\n",
    "        asyncio.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание БД**\n",
    "- Задача решена с партизированием по месяцам -- было бы полезно, если бы прогнозные данные загружались регулярно -- и с индексированием по городам для ускорения поиска по городу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "Параметры подключения к PostgreSQL\n",
    "\"\"\"\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'weather_db'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'password'\n",
    "\n",
    "\n",
    "def create_postgres_container():\n",
    "    \"\"\"\n",
    "    Создание контейнера Docker с PostgreSQL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.run([\"docker\", \"run\", \"--name\", \"weather_forecast\", \"-e\", f\"POSTGRES_PASSWORD={DB_PASSWORD}\", \"-p\", f\"{DB_PORT}:5432\", \"-d\", \"postgres\"])\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(\"Ошибка при создании контейнера Docker с PostgreSQL:\", e)\n",
    "\n",
    "\n",
    "\n",
    "def create_database():\n",
    "    \"\"\"\n",
    "    Создание базы данных.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD)\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(DB_NAME)))\n",
    "        conn.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при создании базы данных:\", e)\n",
    "\n",
    "\n",
    "\n",
    "def connect_to_database():\n",
    "    \"\"\"\n",
    "    Подключение к базе данных.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD)\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при подключении к базе данных:\", e)\n",
    "\n",
    "\n",
    "\n",
    "def create_schema_and_tables():\n",
    "    \"\"\"\n",
    "    Создание схем и таблиц.\n",
    "    \"\"\"\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        \"\"\"\n",
    "        Создание схемы для приемки сырых данных\n",
    "        \"\"\"\n",
    "        cursor.execute(\"CREATE SCHEMA IF NOT EXISTS raw_data;\")\n",
    "        \n",
    "        \"\"\"\n",
    "        Создание схемы для будущих агрегирующих таблиц\n",
    "        \"\"\"\n",
    "        cursor.execute(\"CREATE SCHEMA IF NOT EXISTS aggregated_data;\")\n",
    "\n",
    "        \"\"\"\n",
    "        Создание таблицы для приемки сырых данных\n",
    "        \"\"\"\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS raw_data.weather (\n",
    "                city VARCHAR,\n",
    "                date DATE,\n",
    "                hour INTEGER,\n",
    "                temperature_c INTEGER,\n",
    "                pressure_mm INTEGER,\n",
    "                is_rainy INTEGER\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        \"\"\"\n",
    "        Партиционирование таблицы по месяцам\n",
    "        \"\"\"\n",
    "        for month in range(1, 13):\n",
    "            cursor.execute(sql.SQL(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS raw_data.weather_{month} (\n",
    "                    CHECK (EXTRACT(MONTH FROM date) = {month})\n",
    "                ) INHERITS (raw_data.weather);\n",
    "            \"\"\").format(month=sql.Literal(month)))\n",
    "\n",
    "        \"\"\"\n",
    "        Индексирование таблицы по городам\n",
    "        \"\"\"\n",
    "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_city ON raw_data.weather (city);\")\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при создании схем и таблиц:\", e)\n",
    "\n",
    "\n",
    "\n",
    "def load_data_from_csv(csv_file):\n",
    "    \"\"\"\n",
    "    Загрузка данных из CSV в PostgreSQL.\n",
    "    \"\"\"\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Пропускаем заголовок\n",
    "            for row in reader:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO raw_data.weather (city, date, hour, temperature_c, pressure_mm, is_rainy)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", row)\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при загрузке данных из CSV в PostgreSQL:\", e)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для выполнения всех задач.\n",
    "    \"\"\"\n",
    "    create_postgres_container()\n",
    "    time.sleep(10)  # Задержка перед созданием базы данных\n",
    "    create_database()\n",
    "    time.sleep(5)   # Задержка перед созданием схем и таблиц\n",
    "    create_schema_and_tables()\n",
    "    time.sleep(5)   # Задержка перед загрузкой данных из CSV\n",
    "    load_data_from_csv(\"weather_forecast_asyncio.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разметка даных и создание витрин**\n",
    "- Поскольку в csv из первой задачи нет прогнозных дней с дождём, записала прогноз дождя рандомно согласно условию.\n",
    "- Сформировала две витрины -- а) с часами начала дождя по городам и б) со скользящими средними по температуре и давлению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "\"\"\"\n",
    "Параметры подключения к PostgreSQL\n",
    "\"\"\"\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'weather_db'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'password'\n",
    "\n",
    "def connect_to_database():\n",
    "    \"\"\"\n",
    "    Подключение к базе данных.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD)\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при подключении к базе данных:\", e)\n",
    "\n",
    "\n",
    "def mark_rainy_days():\n",
    "    \"\"\"\n",
    "    Разметка данных о дожде в таблице raw_data.weather.\n",
    "    \"\"\"\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \"\"\"\n",
    "        Сброс флага дождя для всех записей.\n",
    "        \"\"\"\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE raw_data.weather\n",
    "            SET is_rainy = 0\n",
    "        \"\"\")\n",
    "        \"\"\"\n",
    "        Получаем список уникальных дат.\n",
    "        \"\"\"\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT DISTINCT date\n",
    "            FROM raw_data.weather\n",
    "        \"\"\")\n",
    "        unique_dates = cursor.fetchall()\n",
    "        \n",
    "        rainy_days = set()  # множество для хранения уже размеченных дней\n",
    "        \n",
    "        for date in unique_dates:\n",
    "            if len(rainy_days) >= 7:  # если уже разметили 7 дней, прекращаем\n",
    "                break\n",
    "            \n",
    "            # Получаем случайный город и час для разметки\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT city, hour\n",
    "                FROM raw_data.weather\n",
    "                WHERE date = %s\n",
    "                ORDER BY random()\n",
    "                LIMIT 1\n",
    "            \"\"\", (date,))\n",
    "            row = cursor.fetchone()\n",
    "            if row:\n",
    "                city, hour = row\n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE raw_data.weather\n",
    "                    SET is_rainy = 1,\n",
    "                        hour = %s\n",
    "                    WHERE city = %s AND date = %s\n",
    "                \"\"\", (hour, city, date))\n",
    "                rainy_days.add(date)\n",
    "                \n",
    "        conn.commit()\n",
    "        print(\"Разметка данных о дожде завершена.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при разметке данных о дожде:\", e)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()     \n",
    "\n",
    "\n",
    "def create_views():\n",
    "    \"\"\"\n",
    "    Создание витрин.\n",
    "    \"\"\"\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \"\"\"\n",
    "        Создание витрины с часами начала дождя для каждого города и дня.\n",
    "        \"\"\"\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE VIEW rainy_hours AS\n",
    "            SELECT city, date, hour AS start_hour_of_rain\n",
    "            FROM raw_data.weather\n",
    "            WHERE is_rainy = 1;\n",
    "        \"\"\")\n",
    "        \"\"\"\n",
    "        Создание витрины со скользящим средним по температуре и давлению.\n",
    "        \"\"\"\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE VIEW moving_avg AS\n",
    "            SELECT city, date, hour,\n",
    "                AVG(temperature_c) OVER (PARTITION BY city, date ORDER BY hour ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS temp_moving_avg,\n",
    "                AVG(pressure_mm) OVER (PARTITION BY city, date ORDER BY hour ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS pressure_moving_avg\n",
    "            FROM raw_data.weather;\n",
    "        \"\"\")\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"Создание витрин завершено.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Ошибка при создании витрин:\", e)\n",
    "\n",
    "\n",
    "def export_to_csv(view_name, csv_file):\n",
    "    \"\"\"\n",
    "    Экспорт данных из витрины в CSV файл.\n",
    "    \"\"\"\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \"\"\"\n",
    "        Получаем данные из витрины.\n",
    "        \"\"\"\n",
    "        cursor.execute(f\"SELECT DISTINCT * FROM {view_name}\")\n",
    "        rows = cursor.fetchall()\n",
    "        \"\"\"\n",
    "        Экспортируем данные в CSV файл.\n",
    "        \"\"\"\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([desc[0] for desc in cursor.description])  # записываем заголовок\n",
    "            for row in rows:\n",
    "                if len(row) >= 5:\n",
    "                    writer.writerow([row[0], row[1], row[2], round(row[3], 1), round(row[4], 1)])  # округляем значения\n",
    "                else:\n",
    "                    writer.writerow(row)  # записываем кортеж как есть\n",
    "            print(f\"Экспорт данных из витрины {view_name} в CSV файл завершен.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Ошибка при экспорте данных из витрины {view_name}:\", e)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для выполнения всех задач.\n",
    "    \"\"\"\n",
    "    mark_rainy_days()\n",
    "    time.sleep(5)  # задержка 5 секунд\n",
    "    create_views()\n",
    "    time.sleep(5)  # ещё одна задержка 5 секунд\n",
    "    export_to_csv(\"rainy_hours\", \"rainy_hours.csv\")\n",
    "    export_to_csv(\"moving_avg\", \"moving_average.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**БД для Яндекс.Метрики**\n",
    "\n",
    "1.   Слой сырых данных (Raw Data Layer): сюда можно на регулярной основе складывать данные, полученные из обеих API endpoints как есть. Для этого можно использовать AirFlow, настроив частоту обновлений по необходимости (от 5 минут до раз в час или в день).\n",
    "Для этого слоя данных я бы создала две таблицы *visits_raw* и *pageviews_raw* о визитах и просмотрах страниц соответственно. Каждая таблица содержала бы все поля, описанные в предоставленных данных для визитов и просмотров, а также дополнительные поля для идентификации и обработки данных.\n",
    "\n",
    "2.   На агрегатном слое (Aggregated Data Layer) можно создать почасовые или подневные агрегаты наиболее востребованных данных. Например, можно сделать featurestore с подневными агрегатами на уровне пользователя для задач ML (предсказание оттока, конверсий, look-alike и т.д.). Например, это может быть materialized view, в котором раз в день для каждого пользователя расчитывается число визитов, число просмотров, длительность визитов и просмотров и прочие полезные признаки, которые могут быть использованы в моделях машинного обучения.\n",
    "\n",
    "Примерами других витрин могли бы быть:\n",
    "- daily_visits_summary: суммарная статистика по визитам за каждый день с разбивкой по атрибутам (страницы, utm метки, устройства и т.д.).\n",
    "- daily_pageviews_summary: суммарная статистика по просмотрам страниц за каждый день с разбивкой по атрибутам.\n",
    "- funnel_conversions: данные о конверсиях по воронке с разбивкой по датам, страницам, utm меткам и т.д.\n",
    "\n",
    "3. Для слоя данных, решающего наиболее типовых задач BI (Analytical Data Layer - конверсии, retention, сегменты), лучше всего подойдут materialized view, к которым можно подключить Power BI/Tableau и прочие инструменты. Для ad hoc задач, не входящих в типовые, скорее всего придётся писать view с использованием данных с первого (raw) слоя. апример, можно создать представление utm_campaign_summary, которое объединяет данные из таблиц daily_visits_summary и daily_pageviews_summary для анализа по utm меткам.\n",
    "\n",
    "**Схемы таблиц**\n",
    "\n",
    "*- Таблица visits_raw:*\n",
    "\n",
    "* visitID: Идентификатор визита (UInt64)\n",
    "\n",
    "* counterID: Номер счетчика (UInt32)\n",
    "\n",
    "* date: Дата визита (Date)\n",
    "\n",
    "* dateTime: Дата и время визита (DateTime)\n",
    "...\n",
    "\n",
    "* (другие поля, как указано в исходных данных для визитов)\n",
    "\n",
    "\n",
    "*- Таблица pageviews_raw:*\n",
    "\n",
    "* watchID: Идентификатор просмотра (UInt64)\n",
    "\n",
    "* counterID: Номер счетчика (UInt32)\n",
    "\n",
    "* date: Дата события (Date)\n",
    "\n",
    "* dateTime: Дата и время события (DateTime)\n",
    "...\n",
    "\n",
    "* (другие поля, как указано в исходных данных для просмотров страниц)\n",
    "\n",
    "\n",
    "\n",
    "*- Таблица daily_visits_summary:*\n",
    "\n",
    "* date: Дата (Date)\n",
    "\n",
    "* counterID: Номер счетчика (UInt32)\n",
    "...\n",
    "\n",
    "* (поля для суммарной статистики по визитам)\n",
    "\n",
    "\n",
    "*- Таблица daily_pageviews_summary:*\n",
    "\n",
    "* date: Дата (Date)\n",
    "\n",
    "* counterID: Номер счетчика (UInt32)\n",
    "...\n",
    "\n",
    "* (поля для суммарной статистики по просмотрам страниц)\n",
    "\n",
    "\n",
    "*- Таблица funnel_conversions:*\n",
    "\n",
    "* date: Дата (Date)\n",
    "\n",
    "* counterID: Номер счетчика (UInt32)\n",
    "...\n",
    "\n",
    "* (поля для данных о конверсиях по воронке)\n",
    "\n",
    "\n",
    "*- Таблица marketing_campaigns:*\n",
    "\n",
    "* campaignID: Идентификатор кампании (UInt32)\n",
    "\n",
    "* campaignName: Название кампании (String)\n",
    "...\n",
    "\n",
    "* (другие поля для дополнительной информации о маркетинговых кампаниях)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
